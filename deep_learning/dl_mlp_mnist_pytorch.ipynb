{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP)\n",
    "\n",
    "## Course outline:\n",
    "\n",
    "1. Recall of linear classifier\n",
    "\n",
    "2. MLP with scikit-learn\n",
    "\n",
    "3. MLP with pytorch\n",
    "\n",
    "4. Test several MLP architectures\n",
    "\n",
    "5. Limits of MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "Deep learning\n",
    "\n",
    "- [cs231n.stanford.edu](http://cs231n.stanford.edu/)\n",
    "\n",
    "\n",
    "Pytorch\n",
    "\n",
    "- [WWW tutorials](https://pytorch.org/tutorials/)\n",
    "- [github tutorials](https://github.com/pytorch/tutorials)\n",
    "- [github examples](https://github.com/pytorch/examples)\n",
    "\n",
    "MNIST and pytorch:\n",
    "\n",
    "- [MNIST nextjournal.com/gkoehler/pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist)\n",
    "- [MNIST github/pytorch/examples](https://github.com/pytorch/examples/tree/master/mnist)\n",
    "- [MNIST kaggle](https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "WD = os.path.join(Path.home(), \"data\", \"pystatml\", \"dl_mnist_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "no_cuda = True\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: MNIST Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size_train, batch_size_test):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)) # Mean and Std of the MNIST dataset\n",
    "                       ])),\n",
    "        batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,)) # Mean and Std of the MNIST dataset\n",
    "        ])),\n",
    "        batch_size=batch_size_test, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_mnist(batch_size_train, batch_size_test)\n",
    "data_shape = train_loader.dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "D_out = len(train_loader.dataset.targets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train dataset:\", train_loader.dataset.data.shape, train_loader.dataset.targets.shape)\n",
    "print(\"Test dataset:\", test_loader.dataset.data.shape, test_loader.dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at some mini-batches examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, (example_data, example_targets) = next(enumerate(train_loader))\n",
    "print(\"Train batch:\", example_data.shape, example_targets.shape)\n",
    "batch_idx, (example_data, example_targets) = next(enumerate(test_loader))\n",
    "print(\"Test batch:\", example_data.shape, example_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So one test data batch is a tensor of shape: . This means we have 1000 examples of 28x28 pixels in grayscale\n",
    "(i.e. no rgb channels, hence the one). We can plot some of them using matplotlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_label_prediction(data, y_true, y_pred=None, shape=(2, 3)):\n",
    "    y_pred = [None] * len(y_true) if y_pred is None else y_pred\n",
    "    fig = plt.figure()\n",
    "    for i in range(np.prod(shape)):\n",
    "        plt.subplot(*shape, i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(data[i][0], cmap='gray', interpolation='none')\n",
    "        plt.title(\"True: {} Pred: {}\".format(y_true[i], y_pred[i]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "show_data_label_prediction(data=example_data, y_true=example_targets, y_pred=None, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall of linear classifier\n",
    "\n",
    "### Binary logistic regression\n",
    "\n",
    "<img src=\"figures/logistic.png\" width=\"300\">\n",
    "\n",
    "1 neuron as output layer\n",
    "$$\n",
    "f(x) = \\sigma(x^{T} w)\n",
    "$$\n",
    "\n",
    "\n",
    "### Softmax Classifier (Multinomial Logistic Regression)\n",
    "\n",
    "<img src=\"figures/logistic_multinominal.png\" width=\"300\">\n",
    "\n",
    "- Input $x$: a vector of dimension $(0)$ (layer 0).\n",
    "- Ouput $f(x)$ a vector of $(1)$ (layer 1) possible labels \n",
    "\n",
    "The model as $(1)$ neurons as output layer\n",
    "\n",
    "$$\n",
    "f(x) = \\text{softmax}(x^{T} W + b)\n",
    "$$\n",
    "\n",
    "Where $W$ is a $(0) \\times (1)$ of coefficients and $b$ is a  $(1)$-dimentional vector of bias.\n",
    "\n",
    "MNIST classfification using multinomial logistic\n",
    "\n",
    "<img src=\"figures/logistic_multinominal_MNIST.png\" width=\"800\">\n",
    "\n",
    "[source: Logistic regression MNIST](https://notebooks.azure.com/cntk/projects/edxdle/html/Lab2_LogisticRegression.ipynb)\n",
    "\n",
    "Here we fit a multinomial logistic regression with L2 penalty on a subset of\n",
    "the MNIST digits classification task.\n",
    "\n",
    "[source: scikit-learn.org](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_loader.dataset.data.numpy()\n",
    "#print(X_train.shape)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "y_train = train_loader.dataset.targets.numpy()\n",
    "\n",
    "X_test = test_loader.dataset.data.numpy()\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "y_test = test_loader.dataset.targets.numpy()\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Turn up tolerance for faster convergence\n",
    "clf = LogisticRegression(C=50., multi_class='multinomial', solver='sag', tol=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "#sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "score = clf.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "#print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
    "print(\"Test score with penalty: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf.coef_.copy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(10):\n",
    "    l1_plot = plt.subplot(2, 5, i + 1)\n",
    "    l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
    "                   cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l1_plot.set_xlabel('Class %i' % i)\n",
    "plt.suptitle('Classification vector for...')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Two Layer MLP\n",
    "\n",
    "### MLP with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, ), max_iter=n_epochs, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=learning_rate, batch_size=batch_size_train)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "\n",
    "print(\"Coef shape=\", len(mlp.coefs_))\n",
    "\n",
    "fig, axes = plt.subplots(4, 4)\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_in, d_hidden)\n",
    "        self.linear2 = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.linear1(X)\n",
    "        return F.log_softmax(self.linear2(X), dim=1)\n",
    "\n",
    "model = TwoLayerMLP(D_in, 50, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the model and compute the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "\n",
    "- First we want to make sure our network is in training mode.\n",
    "\n",
    "- Then we iterate over all training data once per epoch. Loading the individual batches is handled by the DataLoader.\n",
    "\n",
    "- First we need to manually set the gradients to zero using `optimizer.zero_grad()` since PyTorch by default accumulates gradients.\n",
    "\n",
    "- Forward pass: We  produce the output of our network and compute a negative log-likelihodd loss between the output and the ground truth label.\n",
    "\n",
    "- Backward pass: The `backward()` call we now collect a new set of gradients which we propagate back into each of the network's parameters using `optimizer.step()`.\n",
    "\n",
    "- We'll also keep track of the progress with some printouts. In order to create a nice training curve later on we also create two lists for saving training and testing losses. On the x-axis we want to display the number of training examples the network has seen during training.\n",
    "\n",
    "- Save model state: Neural network modules as well as optimizers have the ability to save and load their internal state using `.state_dict()`. With this we can continue training from previously saved state dicts if needed - we'd just need to call `.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, device, log_interval=10, batch_max=np.inf, save_model=True):\n",
    "    train_losses, train_counter = list(), list()\n",
    "    # epoch = 1; log_interval=10; train_losses=[]; train_counter=[]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over minibatch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > batch_max:\n",
    "            break\n",
    "        # batch_idx, (data, target) = next(enumerate(train_loader))\n",
    "        # print(data.shape)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "    \n",
    "        # Bakward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(data.shape[0]) # (batch_idx * data.shape[0]) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "        # Save model\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            if save_model:\n",
    "                torch.save(model.state_dict(), 'models/mod-%s.pth' % model.__class__.__name__)\n",
    "                torch.save(optimizer.state_dict(), \n",
    "                           'models/mod-%s_opt-%s.pth' % (model.__class__.__name__,\n",
    "                                                         optimizer.__class__.__name__))\n",
    "\n",
    "    return model, train_losses, train_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate/test the Model\n",
    "\n",
    "- First we want to make sure our network is in evaluation mode `model.eval()`.\n",
    "\n",
    "- Then we iterate over all test data once per epoch. Loading the individual batches is handled by the DataLoader.\n",
    "\n",
    "- Using the context manager `torch.no_grad()` we can avoid storing the computations done producing the output of our network in the computation graph.\n",
    "\n",
    "Test loop. Here we sum up the test loss and keep track of correctly classified digits to compute the accuracy of\n",
    "the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device, batch_max=np.inf):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    output, pred, target = list(), list(), list()\n",
    "\n",
    "    # Iterate over mini-batches\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target_) in enumerate(test_loader):\n",
    "            if batch_idx > batch_max:\n",
    "                break\n",
    "            # batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "            # print(target_.shape)\n",
    "            data, target_ = data.to(device), target_.to(device) # target.shape == 1000\n",
    "            output_ = model(data) # output.shape == (1000, 10)\n",
    "            \n",
    "            # Compute loss\n",
    "            test_loss += F.nll_loss(output_, target_, reduction='sum').item() # sum up batch loss\n",
    "            pred_ = output_.argmax(dim=1) # get the index of the max log-probability\n",
    "            \n",
    "            # An correct classification\n",
    "            correct += pred_.eq(target_.view_as(pred_)).sum().item() # view_as(other): View this tensor as the same size as other\n",
    "\n",
    "            # Track output, class-prediction and true target\n",
    "            output.append(output_)\n",
    "            pred.append(pred_)\n",
    "            target.append(target_)\n",
    "\n",
    "    output = torch.cat(output)\n",
    "    pred = torch.cat(pred)\n",
    "    target = torch.cat(target)\n",
    "    assert pred.eq(target.view_as(pred)).sum().item() == correct\n",
    "\n",
    "    test_loss /= len(target)\n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)'.format(\n",
    "        test_loss, correct, len(target),\n",
    "        100. * correct / len(target)))\n",
    "    return pred, output, target, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the network and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If we were using a GPU for training, we should have also sent the network parameters to the GPU\n",
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to run the training! We'll manually add a test() call before we loop over n_epochs to evaluate our model with\n",
    "randomly initialized parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, output, target, test_loss = test(model, test_loader, device)\n",
    "print(\"Test accuracy = {}%\".format((target == pred).sum() * 100. / len(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_losses, train_counter = train(model, train_loader, optimizer, 1, device, log_interval=100)\n",
    "pred, output, target, test_loss = test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model's Performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy = {}%\".format((target == pred).sum() * 100. / len(target)))\n",
    "test_counter, test_losses = [len(train_loader.dataset)], [test_loss]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, '-b',\n",
    "         np.cumsum(test_counter), test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's again look at a few examples as we did earlier and compare the model's output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = model(example_data)\n",
    "y_pred = output.argmax(dim=1)\n",
    "\n",
    "show_data_label_prediction(data=example_data, y_true=example_targets, y_pred=y_pred, shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some missclassified images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = example_targets != y_pred\n",
    "print(\"Nb errors = {}, (rate = {:.2f}%)\".format(errors.sum(), 100 * errors.sum().item() / len(errors)))\n",
    "err_idx = np.where(errors)\n",
    "show_data_label_prediction(data=example_data[err_idx], y_true=example_targets[err_idx], y_pred=y_pred[err_idx], shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "model.load_state_dict(torch.load('models/mod-%s.pth' % model.__class__.__name__))\n",
    "optimizer.load_state_dict(torch.load('models/mod-%s_opt-%s.pth' % (model.__class__.__name__, optimizer.__class__.__name__)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue training from checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2, n_epochs + 1):\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device,\n",
    "                                                 log_interval=50)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    # Test\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(len(train_loader.dataset))\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(np.cumsum(test_counter), test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test several MLP architectures\n",
    "\n",
    "- Define a `MultiLayerMLP(784, 512, 256, 128)` class that take the size of the layer as paraameters of the constructor.\n",
    "- Add some non-linearity with relu acivation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, d_layer):\n",
    "        super(MLP, self).__init__()\n",
    "        self.d_layer = d_layer\n",
    "        layer_list = [nn.Linear(d_layer[l], d_layer[l+1]) for l in range(len(d_layer) - 1)]\n",
    "        self.linears = nn.ModuleList(layer_list)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_layer[0])\n",
    "        # relu(Wl x) for all hidden layer\n",
    "        for layer in self.linears[:-1]:\n",
    "            X = F.relu(layer(X))\n",
    "        # softmax(Wl x) for output layer\n",
    "        return F.log_softmax(self.linears[-1](X), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MLP([D_in, 50, D_out])\n",
    "#model = MLP([D_in, 512, 256, 128, D_out])\n",
    "model = MLP([D_in, 512, 256, 128, 64, D_out]) # 96.6% (5 epochs)\n",
    "#model = MLP([D_in, 512, 256, 256, 128, 128, 64, 64, D_out]) # 98.0% 661514 parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device,\n",
    "                                                 log_interval=100)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    print(\"Test : \", end = '')\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(test_loss)\n",
    "    #print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the size of training dataset\n",
    "\n",
    "Reduce the size of the training dataset by considering only a subset of batches.\n",
    "Reduce the size of the batch size to `16`, an consider `8` mini-batches for training, ie 128 traning samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_mnist(16, batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "n_batch = 8\n",
    "\n",
    "model = MLP([D_in, 512, 256, 128, 64, D_out]) # 11.5% (50 epochs)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print()\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device,\n",
    "                                                 log_interval=8,\n",
    "                                                 batch_max=n_batch, save_model=False)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    print(\"Test : \", end = '')\n",
    "    pred_test, output_test, target_test, loss_test = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(loss_test)\n",
    "    \n",
    "    # Train accuracy\n",
    "    print(\"Train: \", end = '')\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device, batch_max=n_batch)\n",
    "\n",
    "    #print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    #print(\"Test accuracy = {:.1f}%\".format((target_test == pred_test).sum().item() * 100. / len(target_test)))\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MLP on CIFAR-10 dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each:\n",
    "- airplane \t\t\t\t\t\t\t\t\t\t\n",
    "- automobile \t\t\t\t\t\t\t\t\t\t\n",
    "- bird \t\t\t\t\t\t\t\t\t\t\n",
    "- cat \t\t\t\t\t\t\t\t\t\t\n",
    "- deer \t\t\t\t\t\t\t\t\t\t\n",
    "- dog \t\t\t\t\t\t\t\t\t\t\n",
    "- frog \t\t\t\t\t\t\t\t\t\t\n",
    "- horse \t\t\t\t\t\t\t\t\t\t\n",
    "- ship \t\t\t\t\t\t\t\t\t\t\n",
    "- truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "WD = os.path.join(Path.home(), \"data\", \"pystatml\", \"dl_cifar10_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "# An implementation of https://arxiv.org/pdf/1512.03385.pdf                    #\n",
    "# See section 4.2 for the model architecture on CIFAR-10                       #\n",
    "# Some part of the code was referenced from below                              #\n",
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py   #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output layer size: How many classes to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = train_loader.dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "print(train_loader.dataset.data.shape, D_in, data_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output layer size: How many classes to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_out = len(set(train_loader.dataset.targets))\n",
    "print(D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "model = MLP([D_in, 512, 256, 128, 64, D_out]) # 13.6% (10 epochs)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print()\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device,\n",
    "                                                 log_interval=100)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    print(\"Test : \", end = '')\n",
    "    pred_test, output_test, target_test, loss_test = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(loss_test)\n",
    "    \n",
    "    # Train accuracy\n",
    "    print(\"Train: \", end = '')\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device, batch_max=n_batch)\n",
    "\n",
    "    #print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    #print(\"Test accuracy = {:.1f}%\".format((target_test == pred_test).sum().item() * 100. / len(target_test)))\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does dropout regularization improve the situation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDropOut(nn.Module):\n",
    "\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(MLPDropOut, self).__init__()\n",
    "        self.fc1 = nn.Linear(D_in, 512)\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc3_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc4_drop = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc5 = nn.Linear(64, D_out)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, D_in)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc3_drop(x)\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc4_drop(x)\n",
    "\n",
    "        return F.log_softmax(self.fc5(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPDropOut(D_in, D_out)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print()\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval,\n",
    "                                                 batch_max=10)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    # Test\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Train accuracy\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device)\n",
    "    #print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    #print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
