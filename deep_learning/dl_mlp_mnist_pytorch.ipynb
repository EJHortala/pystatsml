{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "Deep learning\n",
    "\n",
    "- [cs231n.stanford.edu](http://cs231n.stanford.edu/)\n",
    "\n",
    "\n",
    "Pytorch\n",
    "\n",
    "- [WWW tutorials](https://pytorch.org/tutorials/)\n",
    "- [github tutorials](https://github.com/pytorch/tutorials)\n",
    "- [github examples](https://github.com/pytorch/examples)\n",
    "\n",
    "MNIST and pytorch:\n",
    "\n",
    "- [MNIST nextjournal.com/gkoehler/pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist)\n",
    "- [MNIST github/pytorch/examples](https://github.com/pytorch/examples/tree/master/mnist)\n",
    "- [MNIST kaggle](https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "WD = os.path.join(tempfile.gettempdir(), \"dl_cnn_mnist_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "no_cuda = True\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: MNIST Handwritten Digit Recognition in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size_train, batch_size_test):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size_test, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_mnist(batch_size_train, batch_size_test)\n",
    "data_shape = train_loader.dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "D_out = len(train_loader.dataset.targets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train dataset:\", train_loader.dataset.data.shape, train_loader.dataset.targets.shape)\n",
    "print(\"Test dataset:\", test_loader.dataset.data.shape, test_loader.dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at some mini-batches examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, (example_data, example_targets) = next(enumerate(train_loader))\n",
    "print(\"Train batch:\", example_data.shape, example_targets.shape)\n",
    "batch_idx, (example_data, example_targets) = next(enumerate(test_loader))\n",
    "print(\"Test batch:\", example_data.shape, example_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So one test data batch is a tensor of shape: . This means we have 1000 examples of 28x28 pixels in grayscale\n",
    "(i.e. no rgb channels, hence the one). We can plot some of them using matplotlib.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_data_label_prediction(data, y_true, y_pred=None, shape=(2, 3)):\n",
    "    y_pred = [None] * len(y_true) if y_pred is None else y_pred\n",
    "    fig = plt.figure()\n",
    "    for i in range(np.prod(shape)):\n",
    "        plt.subplot(*shape, i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(data[i][0], cmap='gray', interpolation='none')\n",
    "        plt.title(\"True: {} Pred: {}\".format(y_true[i], y_pred[i]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "show_data_label_prediction(data=example_data, y_true=example_targets, y_pred=None, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Two Layer MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super(TwoLayerMLP, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_in, d_hidden)\n",
    "        self.linear2 = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_in)\n",
    "        X = self.linear1(X)\n",
    "        return F.log_softmax(self.linear2(X), dim=1)\n",
    "\n",
    "model = TwoLayerMLP(D_in, 50, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the model and compute the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "- First we want to make sure our network is in training mode.\n",
    "\n",
    "- Then we iterate over all training data once per epoch. Loading the individual batches is handled by the DataLoader.\n",
    "\n",
    "- First we need to manually set the gradients to zero using `optimizer.zero_grad()` since PyTorch by default accumulates gradients.\n",
    "\n",
    "- Forward pass: We  produce the output of our network and compute a negative log-likelihodd loss between the output and the ground truth label.\n",
    "\n",
    "- Backward pass: The `backward()` call we now collect a new set of gradients which we propagate back into each of the network's parameters using `optimizer.step()`.\n",
    "\n",
    "- We'll also keep track of the progress with some printouts. In order to create a nice training curve later on we also create two lists for saving training and testing losses. On the x-axis we want to display the number of training examples the network has seen during training.\n",
    "\n",
    "- Save model state: Neural network modules as well as optimizers have the ability to save and load their internal state using `.state_dict()`. With this we can continue training from previously saved state dicts if needed - we'd just need to call `.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, device, log_interval=10, batch_max=np.inf):\n",
    "    train_losses, train_counter = list(), list()\n",
    "    # epoch = 1; log_interval=10; train_losses=[]; train_counter=[]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over minibatch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > batch_max:\n",
    "            break\n",
    "        # batch_idx, (data, target) = next(enumerate(train_loader))\n",
    "        # print(data.shape)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "    \n",
    "        # Bakward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(data.shape[0]) # (batch_idx * data.shape[0]) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "        # Save model\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "            torch.save(model.state_dict(), 'models/mod-%s.pth' % model.__class__.__name__)\n",
    "            torch.save(optimizer.state_dict(), 'models/mod-%s_opt-%s.pth' % (model.__class__.__name__, optimizer.__class__.__name__))\n",
    "\n",
    "    return model, train_losses, train_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate/test the Model\n",
    "\n",
    "- First we want to make sure our network is in evaluation mode `model.eval()`.\n",
    "\n",
    "- Then we iterate over all test data once per epoch. Loading the individual batches is handled by the DataLoader.\n",
    "\n",
    "- Using the context manager `torch.no_grad()` we can avoid storing the computations done producing the output of our network in the computation graph.\n",
    "\n",
    "Test loop. Here we sum up the test loss and keep track of correctly classified digits to compute the accuracy of\n",
    "the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    output, pred, target = list(), list(), list()\n",
    "\n",
    "    # Iterate over mini-batches\n",
    "    with torch.no_grad():\n",
    "        for data, target_ in test_loader:\n",
    "            # batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "            # print(target_.shape)\n",
    "            data, target_ = data.to(device), target_.to(device) # target.shape == 1000\n",
    "            output_ = model(data) # output.shape == (1000, 10)\n",
    "            \n",
    "            # Compute loss\n",
    "            test_loss += F.nll_loss(output_, target_, reduction='sum').item() # sum up batch loss\n",
    "            pred_ = output_.argmax(dim=1) # get the index of the max log-probability\n",
    "            \n",
    "            # An correct classification\n",
    "            correct += pred_.eq(target_.view_as(pred_)).sum().item() # view_as(other): View this tensor as the same size as other\n",
    "\n",
    "            # Track output, class-prediction and true target\n",
    "            output.append(output_)\n",
    "            pred.append(pred_)\n",
    "            target.append(target_)\n",
    "\n",
    "    output = torch.cat(output)\n",
    "    pred = torch.cat(pred)\n",
    "    target = torch.cat(target)\n",
    "    assert pred.eq(target.view_as(pred)).sum().item() == correct\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return pred, output, target, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the network and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If we were using a GPU for training, we should have also sent the network parameters to the GPU\n",
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to run the training! We'll manually add a test() call before we loop over n_epochs to evaluate our model with\n",
    "randomly initialized parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, output, target, test_loss = test(model, test_loader, device)\n",
    "print(\"Test accuracy = {}%\".format((target == pred).sum() * 100. / len(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_losses, train_counter = train(model, train_loader, optimizer, 1, device)\n",
    "pred, output, target, test_loss = test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model's Performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy = {}%\".format((target == pred).sum() * 100. / len(target)))\n",
    "test_counter, test_losses = [len(train_loader.dataset)], [test_loss]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, '-b',\n",
    "         np.cumsum(test_counter), test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's again look at a few examples as we did earlier and compare the model's output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = model(example_data)\n",
    "y_pred = output.argmax(dim=1)\n",
    "\n",
    "show_data_label_prediction(data=example_data, y_true=example_targets, y_pred=y_pred, shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some missclassified images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = example_targets != y_pred\n",
    "print(\"Nb errors = {}, (rate = {:.2f}%)\".format(errors.sum(), 100 * errors.sum().item() / len(errors)))\n",
    "err_idx = np.where(errors)\n",
    "show_data_label_prediction(data=example_data[err_idx], y_true=example_targets[err_idx], y_pred=y_pred[err_idx], shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerMLP(D_in, 50, D_out)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "model.load_state_dict(torch.load('models/mod-%s.pth' % model.__class__.__name__))\n",
    "optimizer.load_state_dict(torch.load('models/mod-%s_opt-%s.pth' % (model.__class__.__name__, optimizer.__class__.__name__)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue training from checkpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2, n_epochs + 1):\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    # Test\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(len(train_loader.dataset))\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(np.cumsum(test_counter), test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test several MLP architectures\n",
    "\n",
    "- Define a `MultiLayerMLP(784, 512, 256, 128)` class that take the size of the layer as paraameters of the constructor.\n",
    "- Add some non-linearity with relu acivation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, d_layer):\n",
    "        super(MultiLayerMLP, self).__init__()\n",
    "        self.d_layer = d_layer\n",
    "        layer_list = [nn.Linear(d_layer[l], d_layer[l+1]) for l in range(len(d_layer) - 1)]\n",
    "        self.linears = nn.ModuleList(layer_list)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, self.d_layer[0])\n",
    "        # relu(Wl x) for all hidden layer\n",
    "        for layer in self.linears[:-1]:\n",
    "            X = F.relu(layer(X))\n",
    "        # softmax(Wl x) for output layer\n",
    "        return F.log_softmax(self.linears[-1](X), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MultiLayerMLP([D_in, 50, D_out])\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 128, D_out])\n",
    "model = MultiLayerMLP([D_in, 512, 256, 128, 64, D_out]) # 97.0% (5 epochs)\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 256, 128, 128, 64, 64, D_out]) # 98.0%\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    # Test\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits of MLP: reduce the size of training dataset\n",
    "\n",
    "Since `batch_size_train = 64` we will only train with 10 first mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MultiLayerMLP([D_in, 50, D_out])\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 128, D_out])\n",
    "model = MultiLayerMLP([D_in, 512, 256, 128, 64, D_out]) # 97.0% (5 epochs)\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 256, 128, 128, 64, 64, D_out]) # 98.0%\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval,\n",
    "                                                 batch_max=10)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    # Test\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Train accuracy\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device)\n",
    "    print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does dropout regularization improve the situation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDropOut(nn.Module):\n",
    "\n",
    "    def __init__(self, D_in, D_out):\n",
    "        super(MLPDropOut, self).__init__()\n",
    "        self.fc1 = nn.Linear(D_in, 512)\n",
    "        self.fc1_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc3_drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc4_drop = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc5 = nn.Linear(64, D_out)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, D_in)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_drop(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_drop(x)\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc3_drop(x)\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc4_drop(x)\n",
    "\n",
    "        return F.log_softmax(self.fc5(x), dim=1)\n",
    "\n",
    "#mlp = MLP()\n",
    "#print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MultiLayerMLP([D_in, 50, D_out])\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 128, D_out])\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 128, 64, D_out]) # 97.0% (5 epochs)\n",
    "#model = MultiLayerMLP([D_in, 512, 256, 256, 128, 128, 64, 64, D_out]) # 98.0%\n",
    "model = MLPDropOut(D_in, D_out)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Train\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval,\n",
    "                                                 batch_max=10)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    # Test\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Train accuracy\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device)\n",
    "    print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
