{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Load dataset\n",
    "2. Architecures general guidelines\n",
    "2. Train and test functions\n",
    "3. CNN models\n",
    " \n",
    "Sources:\n",
    "\n",
    "Deep learning\n",
    "- [cs231n.stanford.edu](http://cs231n.stanford.edu/)\n",
    "\n",
    "CNN\n",
    "- [Stanford cs231n](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "Pytorch\n",
    "- [WWW tutorials](https://pytorch.org/tutorials/)\n",
    "- [github tutorials](https://github.com/pytorch/tutorials)\n",
    "- [github examples](https://github.com/pytorch/examples)\n",
    "\n",
    "MNIST and pytorch:\n",
    "- [MNIST nextjournal.com/gkoehler/pytorch-mnist](https://nextjournal.com/gkoehler/pytorch-mnist)\n",
    "- [MNIST github/pytorch/examples](https://github.com/pytorch/examples/tree/master/mnist)\n",
    "- [MNIST kaggle](https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist)\n",
    "\n",
    "## Architetctures\n",
    "\n",
    "Sources:\n",
    "\n",
    "- [cv-tricks.com](https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception)\n",
    "- [zhenye-na.github.io(]https://zhenye-na.github.io/2018/12/01/cnn-deep-leearning-ai-week2.html)\n",
    "\n",
    "\n",
    "### LeNet\n",
    "\n",
    "The first  Convolutional Networks were developed by Yann LeCun in 1990â€™s.\n",
    "\n",
    "<img src=\"figures/LeNet_Original_Image.jpg\" width=\"1000\">\n",
    "\n",
    "### AlexNet\n",
    "\n",
    "(2012, Alex Krizhevsky, Ilya Sutskever and Geoff Hinton)\n",
    "\n",
    "- Deeper, bigger,\n",
    "- Featured Convolutional Layers stacked on top of each other (previously it was common to only have a single CONV layer always immediately followed by a POOL layer).\n",
    "- **ReLu(Rectified Linear Unit)** for the non-linear part, instead of a Tanh or Sigmoid.\n",
    "\n",
    "The advantage of the ReLu over sigmoid is that it trains much faster than the latter because the derivative of sigmoid becomes very small in the saturating region and therefore the updates to the weights almost vanish. This is called **vanishing gradient problem**.\n",
    "\n",
    "- **Dropout**: reduces the over-fitting by using a Dropout layer after every FC layer. Dropout layer has a probability,(p), associated with it and is applied at every neuron of the response map separately. It randomly switches off the activation with the probability p.  \n",
    "\n",
    "<img src=\"figures/dropout.jpeg\" width=\"500\">\n",
    "\n",
    "Why does DropOut work?\n",
    "\n",
    "The idea behind the dropout is similar to the model ensembles. Due to the dropout layer, different sets of neurons which are switched off, represent a different architecture and all these different architectures are trained in parallel with weight given to each subset and the summation of weights being one. For n neurons attached to DropOut, the number of subset architectures formed is 2^n. So it amounts to prediction being averaged over these ensembles of models. This provides a structured model regularization which helps in avoiding the over-fitting. Another view of DropOut being helpful is that since neurons are randomly chosen, they tend to avoid developing co-adaptations among themselves thereby enabling them to develop meaningful features, independent of others.\n",
    "\n",
    "\n",
    "**GoogLeNet**. (Szegedy et al. from Google 2014) was a Convolutional Network . Its main contribution was the development of an\n",
    "\n",
    "- **Inception Module** that dramatically reduced the number of parameters in the network (4M, compared to AlexNet with 60M).\n",
    "- There are also several followup versions to the GoogLeNet, most recently Inception-v4.\n",
    "\n",
    "**VGGNet**. (Karen Simonyan and Andrew Zisserman 2014)\n",
    "\n",
    "- 16 CONV/FC layers and, appealingly, features an extremely homogeneous architecture.\n",
    "\n",
    "- Only performs 3x3 convolutions and 2x2 pooling from the beginning to the end. Replace large kernel-sized filters(11 and 5 in the first and second convolutional layer, respectively) with multiple 3X3 kernel-sized filters one after another.\n",
    "\n",
    "With a given receptive field(the effective area size of input image on which output depends), multiple stacked smaller size kernel is better than the one with a larger size kernel because multiple non-linear layers increases the depth of the network which enables it to learn more complex features, and that too at a lower cost. For example, three 3X3 filters on top of each other with stride 1 ha a receptive size of 7, but the number of parameters involved is 3*(9^2) in comparison to 49^2 parameters of kernels with a size of 7. \n",
    "\n",
    "- Lot more memory and parameters (140M)\n",
    "\n",
    "**ResNet**. (Kaiming He et al. 2015) Residual Network developed by . It features special \n",
    "\n",
    "- Skip connections\n",
    "- Batch normalization. \n",
    "- State of the art CNN models and are the default choice (as of May 10, 2016). In particular, also see more\n",
    "- Recent developments that tweak the original architecture from Kaiming He et al. Identity Mappings in Deep Residual Networks (published March 2016).\n",
    "\n",
    "[Models in pytorch](https://github.com/pytorch/vision/tree/master/torchvision/models)\n",
    "\n",
    "\n",
    "## Architecures general guidelines\n",
    "\n",
    "- ConvNets stack CONV,POOL,FC layers\n",
    "- Trend towards smaller filters and deeper architectures: stack 3x3, instead of 5x5\n",
    "- Trend towards getting rid of POOL/FC layers (just CONV)\n",
    "- Historically architectures looked like [(CONV-RELU) x N POOL?] x M (FC-RELU) x K, SOFTMAX where N is usually up to ~5, M is large, 0 <= K <= 2.\n",
    "- but recent advances such as ResNet/GoogLeNet have challenged this paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "WD = os.path.join(tempfile.gettempdir(), \"dl_cnn_mnist_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "no_cuda = True\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset: MNIST Handwritten Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size_train, batch_size_test):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size_train, shuffle=True)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size_test, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = load_mnist(batch_size_train, batch_size_test)\n",
    "data_shape = train_loader.dataset.data.shape[1:]\n",
    "D_in = np.prod(data_shape)\n",
    "D_out = len(train_loader.dataset.targets.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, device, log_interval=10, batch_max=np.inf, save_model=True):\n",
    "    train_losses, train_counter = list(), list()\n",
    "    # epoch = 1; log_interval=10; train_losses=[]; train_counter=[]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over minibatch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > batch_max:\n",
    "            break\n",
    "        # batch_idx, (data, target) = next(enumerate(train_loader))\n",
    "        # print(data.shape)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "    \n",
    "        # Bakward\n",
    "        loss.backward()\n",
    "\n",
    "        # Update params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(data.shape[0]) # (batch_idx * data.shape[0]) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "        # Save model\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            if save_model:\n",
    "                torch.save(model.state_dict(), 'models/mod-%s.pth' % model.__class__.__name__)\n",
    "                torch.save(optimizer.state_dict(), 'models/mod-%s_opt-%s.pth' % (model.__class__.__name__, optimizer.__class__.__name__))\n",
    "\n",
    "    return model, train_losses, train_counter\n",
    "\n",
    "\n",
    "def test(model, test_loader, device, batch_max=np.inf):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    output, pred, target = list(), list(), list()\n",
    "\n",
    "    # Iterate over mini-batches\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target_) in enumerate(test_loader):\n",
    "            if batch_idx > batch_max:\n",
    "                break\n",
    "            # batch_idx, (data, target) = next(enumerate(test_loader))\n",
    "            # print(target_.shape)\n",
    "            data, target_ = data.to(device), target_.to(device) # target.shape == 1000\n",
    "            output_ = model(data) # output.shape == (1000, 10)\n",
    "            \n",
    "            # Compute loss\n",
    "            test_loss += F.nll_loss(output_, target_, reduction='sum').item() # sum up batch loss\n",
    "            pred_ = output_.argmax(dim=1) # get the index of the max log-probability\n",
    "            \n",
    "            # An correct classification\n",
    "            correct += pred_.eq(target_.view_as(pred_)).sum().item() # view_as(other): View this tensor as the same size as other\n",
    "\n",
    "            # Track output, class-prediction and true target\n",
    "            output.append(output_)\n",
    "            pred.append(pred_)\n",
    "            target.append(target_)\n",
    "\n",
    "    output = torch.cat(output)\n",
    "    pred = torch.cat(pred)\n",
    "    target = torch.cat(target)\n",
    "    assert pred.eq(target.view_as(pred)).sum().item() == correct\n",
    "\n",
    "    test_loss /= len(target)\n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)'.format(\n",
    "        test_loss, correct, len(target),\n",
    "        100. * correct / len(target)))\n",
    "    return pred, output, target, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN models\n",
    "\n",
    "### LeNet-5\n",
    "\n",
    "Here we implement LeNet-5 with relu activation\n",
    "[Source](https://github.com/bollakarthikeya/LeNet-5-PyTorch/blob/master/lenet5_cpu.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network (LeNet-5)  \n",
    "class LeNet5(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self):   \n",
    "        super(LeNet5, self).__init__()\n",
    "        # Convolution (In LeNet-5, 32x32 images are given as input. Hence padding of 2 is done below)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        # Max-pooling\n",
    "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Convolution\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        # Max-pooling\n",
    "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.conv1(x))  \n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_1(x)\n",
    "        # convolve, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.conv2(x))\n",
    "        # max-pooling with 2x2 grid\n",
    "        x = self.max_pool_2(x)\n",
    "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
    "        # read through https://stackoverflow.com/a/42482819/7551231\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        # FC-1, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        # FC-2, then perform ReLU non-linearity\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        # FC-3\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase depth on conv layer, remove one FC, simplify with no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5bis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5bis, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1) \n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(50*4*4, 120) # 500\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # 20 x 24x24 # No padding, loose 4, since kernel size = 5\n",
    "        x = F.max_pool2d(x, 2, 2) # 20 x 12x12\n",
    "        x = F.relu(self.conv2(x)) # 50 x 8x8  # No padding, loose 4, since kernel size = 5\n",
    "        x = F.max_pool2d(x, 2, 2) # 50 x 4x4\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv-relu blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network (LeNet-5)  \n",
    "class ConvNet2Block(torch.nn.Module):\n",
    "     \n",
    "    def __init__(self):   \n",
    "        super(ConvNet2Block, self).__init__()\n",
    "\n",
    "        # Conv block 1\n",
    "        #self.conv11 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        #self.conv12 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv11 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.conv12 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.max_pool_1 = nn.MaxPool2d(kernel_size=2) # output 20*12*12\n",
    "\n",
    "        # Conv block 2\n",
    "        self.conv21 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.conv22 = nn.Conv2d(in_channels=50, out_channels=50, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "        self.max_pool_2 = nn.MaxPool2d(kernel_size=2) # output 50*4*4\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(50*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.leaky_relu(self.conv11(x))\n",
    "        x = nn.functional.leaky_relu(self.conv12(x))\n",
    "        x = self.max_pool_1(x)\n",
    "\n",
    "        x = nn.functional.leaky_relu(self.conv21(x))\n",
    "        x = nn.functional.leaky_relu(self.conv22(x))\n",
    "        x = self.max_pool_2(x)\n",
    "        \n",
    "        # first flatten 'max_pool_2_out' to contain 32*7*7 columns\n",
    "        # read through https://stackoverflow.com/a/42482819/7551231\n",
    "        x = x.view(-1, 50*4*4)\n",
    "        # FC-1, then perform ReLU non-linearity\n",
    "        x = nn.functional.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "#model = LeNet5() # 98.4% with 61706 parameters\n",
    "model = LeNet5bis() # 99.1% with 122900 parameters\n",
    "#model = ConvNet2Block() # 98.7% with  132750 parameters\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    print(\"Train: \", end = '')\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    print(\"Test : \", end = '')\n",
    "    pred, output, target, test_loss = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    # Train accuracy\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device)\n",
    "    #print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    #print(\"Test accuracy = {:.1f}%\".format((target == pred).sum().item() * 100. / len(target)))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the size of training dataset\n",
    "\n",
    "Reduce the size of the training dataset by considering only a subset of batches.\n",
    "Reduce the size of the batch size to `16`, an consider `8` mini-batches for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_mnist(16, batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "n_batch = 8\n",
    "\n",
    "# model = LeNet5() # 89.2%% with 61706 parameters\n",
    "#model = LeNet5bis() #93.4%\n",
    "model = ConvNet2Block() # 92.4%\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "    \n",
    "train_losses, train_counter, test_losses, test_counter = [], [], [], []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print()\n",
    "    model, train_losses_, train_counter_ = train(model, train_loader, optimizer, epoch, device, log_interval=100,\n",
    "                                                 batch_max=n_batch, save_model=False)\n",
    "    train_losses += train_losses_\n",
    "    train_counter += train_counter_\n",
    "    \n",
    "    print(\"Test : \", end = '')\n",
    "    pred_test, output_test, target_test, loss_test = test(model, test_loader, device)\n",
    "    test_counter.append(np.sum(train_counter))\n",
    "    test_losses.append(loss_test)\n",
    "    \n",
    "    # Train accuracy\n",
    "    print(\"Train: \", end = '')\n",
    "    pred_train, output_train, target_train, loss_train = test(model, train_loader, device, batch_max=n_batch)\n",
    "\n",
    "    #print(\"Train accuracy = {:.1f}%\".format((target_train == pred_train).sum().item() * 100. / len(target_train)))\n",
    "    #print(\"Test accuracy = {:.1f}%\".format((target_test == pred_test).sum().item() * 100. / len(target_test)))\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(np.cumsum(train_counter), train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, \"or\")\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet on CIFAR-10\n",
    "\n",
    "[Source Yunjey Choi](https://github.com/yunjey/pytorch-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WD = os.path.join(tempfile.gettempdir(), \"dl_cnn_cifar10_pytorch\")\n",
    "os.makedirs(WD, exist_ok=True)\n",
    "os.chdir(WD)\n",
    "print(\"Working dir is:\", os.getcwd())\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "# An implementation of https://arxiv.org/pdf/1512.03385.pdf                    #\n",
    "# See section 4.2 for the model architecture on CIFAR-10                       #\n",
    "# Some part of the code was referenced from below                              #\n",
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py   #\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many classes to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_out = len(set(train_loader.dataset.targets))\n",
    "print(D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet Model:\n",
    "\n",
    "Stack multiple resnet blocks\n",
    "\n",
    "\n",
    "\n",
    "Resnet block variants ([Source](http://torch.ch/blog/2016/02/04/resnets.html)):\n",
    "<img src=\"figures/resnets_modelvariants.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# Train the model\n",
    "def train(model, train_loader, optimizer, epoch, device, learning_rate):\n",
    "    # Loss and optimizer\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    curr_lr = learning_rate\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # CrossEntropyLoss() combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "curr_lr = learning_rate\n",
    "\n",
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "acc_train, acc_test = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, epoch, device, learning_rate)\n",
    "    \n",
    "    print(\"Train: \", end = '')\n",
    "    acc_train_ = test(model, train_loader, device)\n",
    "    print(\"Test : \", end = '')\n",
    "    acc_test_ = test(model, test_loader, device)\n",
    "    acc_train.append(acc_train_)\n",
    "    acc_test.append(acc_test_)\n",
    "    \n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'models/mod-%s.ckpt' % model.__class__.__name__)\n",
    "    torch.save(optimizer.state_dict(), 'models/mod-%s_opt-%s.pth' % (model.__class__.__name__, optimizer.__class__.__name__))\n",
    "    # save the current learning rate\n",
    "    np.save(\"models/resnet_lr_epoch.npy\", np.array([curr_lr, epoch]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toward transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, D_out)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#from torch.optim import lr_scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the model\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.shape)\n",
    "\n",
    "print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n",
    "\n",
    "acc_train, acc_test = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_loader, optimizer, epoch, device, learning_rate)\n",
    "    \n",
    "    print(\"Train: \", end = '')\n",
    "    acc_train_ = test(model, train_loader, device)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print(\"Test : \", end = '')\n",
    "    acc_test_ = test(model, test_loader, device)\n",
    "    acc_train.append(acc_train_)\n",
    "    acc_test.append(acc_test_)\n",
    "    \n",
    "    # Decay learning rate\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        curr_lr /= 3\n",
    "        update_lr(optimizer, curr_lr)\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    # torch.save(model.state_dict(), 'models/mod-%s.ckpt' % model.__class__.__name__)\n",
    "    # torch.save(optimizer.state_dict(), 'models/mod-%s_opt-%s.pth' % (model.__class__.__name__, optimizer.__class__.__name__))\n",
    "    # save the current learning rate\n",
    "    # np.save(\"models/resnet_lr_epoch.npy\", np.array([curr_lr, epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
